利用P2P软件(Murder)大规模分发大文件

http://blog.51cto.com/john88wang/1793080
参考链接

当服务器多时，为了管理方便和提升效率，就会用到自动化管理工具（如Ansible）来自动部署和批量分发文件。

    场景描述：目前有50+台服务器，已部署Ansible用于自动化部署和批量分发文件。批量分发文件时，一般把文件传到 Ansible 所在的服务器并通过 copy或者synchronize 模块传输，文件小于100M时，分发正常。当传输大文件时（100M+），受单节点及其带宽的影响，整个分发过程变得非常缓慢，甚至出现Ansible卡死。

使用 Ansible 来分发小文件速度很快，但对于大文件，文件分发就是一个很大的问题。在使用单一分布点和固定出口带宽的情况下，经常存在带宽拥堵、耗费时间长的问题。

对于大文件分发，首先想到的是 BitTorrent ，利用 P2P 协议实现快速分发，节省带宽，提高效率。
P2P软件介绍

为了解决上面的问题，这里我们使用 Murder 。

Murder 是 Twitter 的开源项目，很适合大文件分发。（该项目还能用，但官方已经不再继续维护）

项目介绍中有这么一段话：Large scale server deploys using BitTorrent and the BitTornado library

根据 Murder 开发者的博客，可以知道这个项目的来龙去脉：

    Twitter 在早期便依赖 Capistrano 来进行应用程序的部署，每当有新版本需要发布时，Capistrano 会根据预设好的各种设置和流程到 Twitter 所有的服务器上进行更新的操作。
    在过去服务器还不多的情r下一切都很美好，但随着 Twitter 服务器数量的增长，到了几百台服务器时，事情已经不再像过去一样美好，甚至到后来拥有数千台服务器时，更新的操作会耗费 40 分钟。
    Twitter 针对这个问题，认为问题的关键在于：使用集中式的系统，也就是所有的服务器要轮流排队到同一台版本控制系统上进行代码更新。

    Twitter 最初的想法是将版本控制系统也做出分散式的架构，服务器的代码更新就可以分散到不同的机器来压缩部署时间，但事实上版本控制系统即使分散在多台服务器上，这些服务器要更新文件也同样需要时间。
    因此 Twitter 发现或许需要一个完全去中心化、最好是像 BitTorrent 这样的，利用 P2P 的特点让所有的节点都可以协助进行程序代码的更新。

    从结果来看，在采用了 BitTorrent 的方式来更新代码，部署的时间从 40 分钟大幅减少到只要 12 秒！实在是非常惊人的改善，数千台服务器的代码更新居然只要短短 12 秒就能完成。


Murder 组件介绍

Murder 是基于 BitTornado 来实现的。有以下几个主要组件：

    torrent tracker ：tracker 使用 murder_tracker.py 运行，tracker 实际上是运行中一台服务器上的单个服务，其他任何成员都要依赖它。Murder为了保持简单，并没有实现tracker-less distribution（DHT）功能。tracker 实际上是个迷你的 httpd 服务，存放着BitTorrent客户端需要更新状态的路径。
	
    seeder ：sender 是存放要分发到其他主机的文件的服务器。这些文件存放在 seeder 的一个目录中，Murder 会将这个目录打包成 tgz 格式并创建一个 .torrent 文件（非常小的文件，包含有关这个tgz文件的基本hash信息）。这个 .torrent 文件让各个 peer 节点知道他们下载的是什么文件。同时，tracker 
	会保持跟踪有哪些 .torrent 文件正在被分发。一旦 Murder 开始传输文件，seeder 服务器将是各个 peer 节点获取种子的地方。
	
    peers ：peer 是成百上千需要接收文件的服务器，并且它们之间可以相互传输文件（下载、上传）。一旦一个peer节点下载完整个 tgz 文件，还将继续 seeding 一段时间，防止蜜罐效应。
